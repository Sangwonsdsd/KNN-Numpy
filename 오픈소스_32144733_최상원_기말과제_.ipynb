{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sangwonsdsd/KNN-Numpy/blob/master/%EC%98%A4%ED%94%88%EC%86%8C%EC%8A%A4_32144733_%EC%B5%9C%EC%83%81%EC%9B%90_%EA%B8%B0%EB%A7%90%EA%B3%BC%EC%A0%9C_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTeQhx2ljddR"
      },
      "source": [
        "## Homework\n",
        " - Backbone, localization header, classification header 를 설계해 아래 코드가 작동될 수 있도록 구현해주세요. <br> \n",
        " - 데이터의 크기가 변동되었음으로 해당 변동사항을 확인해주세요.\n",
        " - train 할시 overfeat loss 가 최소 10 이하로 떨어져야 합니다. \n",
        " - 수업 코드에서 제공되었던 mnist_local_generator.py 와 utils.py 을 업로드 해 사용해야 합니다. \n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjJhBK_uh0bV"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Input, Conv2D, MaxPool2D, Dropout, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.losses import CategoricalCrossentropy\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from mnist_local_generator import mnist_localization_generator\n",
        "import matplotlib.pyplot as plt \n",
        "import numpy as np \n",
        "from utils import xywh2xyxy, draw_rectangle\n",
        "import cv2\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.losses import CategoricalCrossentropy, MSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b38ifSRph3Jm"
      },
      "outputs": [],
      "source": [
        "# load mnist dataset\n",
        "# Generate mnist data for localization\n",
        "(train_images, train_cls_true, train_reg_true), (test_images, test_cls_true, test_reg_true) = \\\n",
        "    mnist_localization_generator((128, 128), (128, 128),\n",
        "                                 background=True, \n",
        "                                 image_size_range=(60, 80),\n",
        "                                 image_ratio_range=(0.5, 1.5),\n",
        "                                 n_sample=10000)\n",
        "\n",
        "print(train_images.shape, test_images.shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_reg_cls = np.concatenate([train_reg_true, train_cls_true], axis=-1)"
      ],
      "metadata": {
        "id": "AkYQ18XsiCod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cLEeOLwHh9mE"
      },
      "source": [
        "## Backbone \n",
        " - 아래 Cell Convolution 을 활용한 backbone 코드를 작성해 주세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5VK4UoSiAGZ"
      },
      "outputs": [],
      "source": [
        "K.clear_session()\n",
        "# 아래 코드에 Convolution 을 활용한 backbone 코드를 작성해 주세요"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully convolution NN\n",
        "input_ = Input(shape=(128, 128, 1))\n",
        "print(input_)\n",
        "\n",
        "# Conv stage 1\n",
        "conv_1 = Conv2D(filters=96/8, kernel_size=(11, 11), strides=(4, 4), padding='valid', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(input_)\n",
        "maxp_1 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_1)\n",
        "\n",
        "# Conv stage 2\n",
        "conv_2 = Conv2D(filters=256/8, kernel_size=(5, 5), strides=(1, 1), padding='valid', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_1)\n",
        "maxp_2 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_2)\n",
        "\n",
        "# Conv stage 3\n",
        "conv_3 = Conv2D(filters=512/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_2)\n",
        "\n",
        "# Conv stage 4\n",
        "conv_4 = Conv2D(filters=1024/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_3)\n",
        "# Conv stage 5\n",
        "conv_5 = Conv2D(filters=1024/8, kernel_size=(3, 3), strides=(1, 1), padding='same', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_4)\n",
        "\n",
        "maxp_5 = MaxPool2D(pool_size=(2, 2), strides=(2, 2))(conv_5)"
      ],
      "metadata": {
        "id": "wCuBzb5RG6Cp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxp_5"
      ],
      "metadata": {
        "id": "Tm2wMTbrJoc-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2_7bRfyiJeV"
      },
      "source": [
        "## Localization header\n",
        " - 아래 Cell에 Convolution 을 활용한 localization 예측 코드를 작성해 주세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gLNx4TP6iMqt"
      },
      "outputs": [],
      "source": [
        "# 아래 코드에 Convolution 을 활용한 localization header 파트 코드를 작성해 주세요\n",
        "# Localization head 1\n",
        "conv_6 = Conv2D(filters=4096/8, kernel_size=(2, 2), strides=(1, 1), padding='valid', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_5)\n",
        "\n",
        "# Localization head 2\n",
        "conv_7 = Conv2D(filters=1024/8, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_6)\n",
        "\n",
        "# Localization head 3\n",
        "loc_output = Conv2D(filters=4, kernel_size=(1, 1), strides=(1, 1), padding='same', activation=None)(conv_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M7VpDPGPiZrf"
      },
      "source": [
        "## Classification header\n",
        " - 아래 Cell에 Convolution 을 활용한 localization 예측 코드를 작성해 주세요"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLxD59zJidaw"
      },
      "outputs": [],
      "source": [
        "# 아래 코드에 Convolution 을 활용한 classification header 파트 코드를 작성해 주세요\n",
        "# Classification head 1\n",
        "conv_6 = Conv2D(filters=4096/8, kernel_size=(2, 2), strides=(1, 1), padding='valid', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(maxp_5)\n",
        "\n",
        "# Classification head 2\n",
        "conv_7 = Conv2D(filters=1024/8, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='relu',\n",
        "                kernel_initializer=RandomNormal(0, 0.01), kernel_regularizer=l2(0.00001))(conv_6)\n",
        "\n",
        "# Classification head 3\n",
        "cls_output = Conv2D(filters=11, kernel_size=(1, 1), strides=(1, 1), padding='same', activation='softmax')(conv_7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATDXlyxgjm4U"
      },
      "source": [
        "## Concatenate header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PnBribIriicC"
      },
      "outputs": [],
      "source": [
        "output = Concatenate(axis=-1)([loc_output, cls_output])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YhUqqb5bjp3O"
      },
      "source": [
        "## Define overfeat loss "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5m4wsWOmsvkU"
      },
      "outputs": [],
      "source": [
        "def overfeat_mse(true, pred):\n",
        "    \"\"\"\n",
        "    :param true: ndarray, 4d tensor (NHWC) 단 C=4\n",
        "    :param pred: ndarray or tensor, 4d tensor (NHWC), 단 C=4\n",
        "    :return: mse_, float,\n",
        "    \"\"\"\n",
        "\n",
        "    # slicing classification and regression\n",
        "    mse = MSE(true, pred)\n",
        "    mse_ = tf.math.reduce_mean(mse)\n",
        "\n",
        "    return mse_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j_1o1uYVu7Cw"
      },
      "outputs": [],
      "source": [
        "def overfeat_cee(true, pred):\n",
        "    \"\"\"\n",
        "    :param true: ndarray, 4d tensor (NHWC) 단 C=11\n",
        "    :param pred: ndarray or tensor, 4d tensor (NHWC), 단 C=11\n",
        "    :return: cee_, float,\n",
        "    \"\"\"\n",
        "\n",
        "    cee = CategoricalCrossentropy()\n",
        "    cee_ = cee(true, pred)\n",
        "\n",
        "    return cee_ "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vmwSeHbXr3bv"
      },
      "outputs": [],
      "source": [
        "def overfeat_loss(true, pred):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    \"\"\"\n",
        "\n",
        "    true_reg = true[:, :, :, :4]\n",
        "    true_cls = true[:, :, :, 4:]\n",
        "\n",
        "    pred_reg = pred[:, :, :, :4]\n",
        "    pred_cls = pred[:, :, :, 4:]\n",
        "\n",
        "    # positive 인 data의 loss 만 localization loss 에 추가 \n",
        "    pos_mask = true_cls[:, :, :, -1] != 1   \n",
        "    pos_true_reg = true_reg[pos_mask]\n",
        "    pos_pred_reg = pred_reg[pos_mask]\n",
        "\n",
        "    mse_loss = overfeat_mse(pos_true_reg, pos_pred_reg)\n",
        "    cee_loss = overfeat_cee(true_cls, pred_cls)\n",
        "\n",
        "    total_loss = mse_loss*0.01 + cee_loss*2\n",
        "    return total_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eOvVylAfw_B_"
      },
      "outputs": [],
      "source": [
        "def metric_mse(true, pred):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    \"\"\"\n",
        "\n",
        "    true_reg = true[:, :, :, :4]\n",
        "    true_cls = true[:, :, :, 4:]\n",
        "    pred_cls = pred[:, :, :, 4:]\n",
        "    pred_reg = pred[:, :, :, :4]\n",
        "\n",
        "    # positive 인 data의 loss 만 localization loss 에 추가 \n",
        "    pos_mask = true_cls[:, :, :, -1] != 1   \n",
        "    pos_true_reg = true_reg[pos_mask]\n",
        "    pos_pred_reg = pred_reg[pos_mask]\n",
        "\n",
        "    mse_loss = overfeat_mse(pos_true_reg, pos_pred_reg)\n",
        "    return mse_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i-XPioEpw-am"
      },
      "outputs": [],
      "source": [
        "def metric_cee(true, pred):\n",
        "    \"\"\"\n",
        "    Description:\n",
        "    :param true: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    :param pred: ndarray, shape = (N, 1, 1, 15=(4+11))\n",
        "    \"\"\"\n",
        "    true_cls = true[:, :, :, 4:]\n",
        "    pred_cls = pred[:, :, :, 4:]\n",
        "    cee_loss = overfeat_cee(true_cls, pred_cls)\n",
        "\n",
        "    return cee_loss\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUAV8nw5it7m"
      },
      "source": [
        "## Compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zUuxjMdWrgM7"
      },
      "outputs": [],
      "source": [
        "# generate keras model\n",
        "model = Model(input_, output)\n",
        "model.compile(optimizer='adam', loss=overfeat_loss, metrics=[metric_mse, metric_cee])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RD7E9b4jIPF"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTeAbUy5ziVK"
      },
      "outputs": [],
      "source": [
        "model.fit(train_images, train_reg_cls, batch_size=32, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln6EYgd6jPpj"
      },
      "source": [
        "## Predict Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkQFdUJm205o"
      },
      "outputs": [],
      "source": [
        "pred_loc_cls = model.predict(test_images[:10])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Ina2i0KjXH6"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDIlRyZT7Lro"
      },
      "outputs": [],
      "source": [
        "pred_loc = pred_loc_cls[:, ..., :4]\n",
        "pred_cls = pred_loc_cls[:, ..., 4:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYQ_wJBr7N-4"
      },
      "outputs": [],
      "source": [
        "pred_loc = np.squeeze(pred_loc)\n",
        "pred_cls = np.argmax(pred_cls, axis=-1)\n",
        "pred_cls = np.squeeze(pred_cls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WG-NiADe7ZdK"
      },
      "outputs": [],
      "source": [
        "pred_loc = xywh2xyxy(pred_loc)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gi6j9tlF7ajH"
      },
      "outputs": [],
      "source": [
        "index = 5\n",
        "rected_image = draw_rectangle(test_images[index, ..., 0], pred_loc[index])\n",
        "plt.imshow(rected_image)\n",
        "plt.title(pred_cls[index])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G3lJjCeE7dSB"
      },
      "outputs": [],
      "source": [
        "model.save('./best_model.h5')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "오픈소스 32144733 최상원 기말과제 .ipynb",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}